{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c31c2f7",
   "metadata": {},
   "source": [
    "## Import libaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be192f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maisha/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/Users/maisha/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:61: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "%pylab inline\n",
    "import numpy as np\n",
    "from random import *\n",
    "from numpy import *\n",
    "from random import *\n",
    "import numpy.linalg as la\n",
    "from scipy.linalg import eig\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score, f1_score\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import preprocessing\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from statsmodels.miscmodels.ordinal_model import OrderedModel\n",
    "from sklearn.model_selection import cross_validate\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1f91fc",
   "metadata": {},
   "source": [
    "## Function for import data and merge the datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e039c613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(filename):\n",
    "    \"\"\"\n",
    "    This function is used how to import a dataset from a file.\n",
    "    \"\"\"\n",
    "    data=pd.read_csv(filename)\n",
    "    return data\n",
    "def drop_rows(df, n):\n",
    "    \"\"\"\n",
    "    This is the function for remove rows from a dataframe. \n",
    "    \"\"\"\n",
    "    return df.iloc[:-n] if n < len(df) else pd.DataFrame(columns=df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db92d6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='Anthropometry_and_diabetes.csv'\n",
    "data= pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "99bf4cbf-230c-40ef-b35e-f0ed0d9a8d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Total Number of diabetic people\n",
    "diabetic_count = data[(data['dibaHbA1C'] ==1)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4c27b6c5-4900-4a8c-a689-65ce1ab473a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Total Number of hypertension people\n",
    "hypertension_count = data[(data['htnbin'] ==1 )].shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c030e93a-2b4b-4781-81cc-8d858ced1bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Total Number of ability to work people \n",
    "ability_to_work_count = data[(data['binary_ability'] ==1 )].shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac7596e",
   "metadata": {},
   "source": [
    "##  Train and Test Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8afc213c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e466328e",
   "metadata": {},
   "source": [
    "## Function for finding participant characteristics (mean, median, standard deviation, maximum, minimum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e502529",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data[['age2018','Weight_kg','Height_cm','BMI','WholeBodyFatPerc','TrunkPerc','meangripboth','generate waistc','generate waisthp','generate waistht','generate_hipc']]\n",
    "def basic_property(X):\n",
    "    '''\n",
    "    This function is used to compute the characteristics such as mean,median, standard deviation, maximum, and minimum\n",
    "    of the participant from the dataset.\n",
    "    '''\n",
    "  \n",
    "    mean=X.mean() #mean\n",
    "    median=X.median() #median\n",
    "    stndd=X.std()#standard deviation\n",
    "    maximum=X.max() # maximum\n",
    "    minimum=X.min() #minimum \n",
    "    return mean, median, stndd,maximum,minimum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b94571",
   "metadata": {},
   "source": [
    "## Decision tree classification  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acaade49-a3b7-4c88-b30e-42770c0c5c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data[['Weight_kg','Height_cm','BMI','WholeBodyFatPerc','TrunkPerc','meangripboth','generate waistc','generate waisthp','generate waistht','generate_hipc']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb472a7f-72ac-4388-94e6-2acb0f841130",
   "metadata": {},
   "source": [
    "## Test Data y is changed according to the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b78c3a-03e7-4e15-a0ac-b57dd232de88",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data['dibaHbA1C'] # For Diabetes\n",
    "y=data['htnbin'] # For Hypertension\n",
    "y=data['binary_ability']  # For ability to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3311868b-f438-41a4-b07b-32c8ef36b29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decisiontreeclassification(X_train, y_train):\n",
    "    '''\n",
    "    This function is used to find the feature importance of the variable by decision tree classifier.\n",
    "    '''\n",
    "    clf = DecisionTreeClassifier(random_state=42, class_weight=\"balanced\")\n",
    "    output = cross_validate(clf, X_train, y_train, cv=3, return_estimator=True)\n",
    "\n",
    "    all_importances = []\n",
    "    for estimator in output['estimator']:\n",
    "        all_importances.append(estimator.feature_importances_)\n",
    "\n",
    "    mean_importance = np.mean(all_importances, axis=0)\n",
    "    std_importance = np.std(all_importances, axis=0)\n",
    "\n",
    "    feature_importances = pd.DataFrame({\n",
    "        'importance_mean': mean_importance,\n",
    "        'importance_std': std_importance\n",
    "    }, index=X_train.columns).sort_values('importance_mean', ascending=False)\n",
    "\n",
    "    return feature_importances\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf25219",
   "metadata": {},
   "source": [
    "## Logistic regression models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b4c461c-f865-46f1-89dd-0276178d4718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1 for Diabetes\n",
    "X1=data[['age2018','generate waistc','generate waisthp','Weight_kg','Height_cm','BMI']]\n",
    "# Model 2 for Diabetes\n",
    "X2=data[['age2018','generate waistc','generate waisthp','Weight_kg','Height_cm']]\n",
    "# Model 3 for Diabetes\n",
    "X3=data[['age2018','generate waistc','generate waisthp','Weight_kg']]\n",
    "# Model 4 for Diabetes\n",
    "X4=data[['age2018','generate waistc','generate waisthp']]\n",
    "# Model 5 for Diabetes\n",
    "X5=data[['age2018','generate waistc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11262cc7-c048-486c-b0cf-12a467c73544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1 for Hypertension\n",
    "X1=data[['age2018','WholeBodyFatPerc','generate waistht','generate waisthp','generate_hipc','generate waistc']]\n",
    "# Model 2 for Hypertension\n",
    "X2=data[['age2018','WholeBodyFatPerc','generate waistht','generate waisthp','generate_hipc']]\n",
    "# Model 3 for Hypertension\n",
    "X3=data[['age2018','WholeBodyFatPerc','generate waistht','generate waisthp']]\n",
    "# Model 4 for Hypertension\n",
    "X4=data[['age2018','WholeBodyFatPerc','generate waistht']]\n",
    "# Model 5 for Hypertension\n",
    "X5=data[['age2018','WholeBodyFatPerc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ba2eea1-0fd8-4a66-87f3-1c259fc94638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1 for ability to work\n",
    "X1=data[['age2018','BMI','meangripboth','generate_hipc','TrunkPerc','Weight_kg']]\n",
    "# Model 2 for ability to work\n",
    "X2=data[['age2018','BMI','meangripboth','generate_hipc','TrunkPerc']]\n",
    "# Model 3 for ability to work\n",
    "X2=data[['age2018','BMI','meangripboth','generate_hipc']]\n",
    "# Model 4 for ability to work\n",
    "X4=data[['age2018','BMI','meangripboth']]\n",
    "# Model 5 for ability to work\n",
    "X4=data[['age2018','BMI']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b99b3dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticregresssionmodel(X_train, y_train):\n",
    "    '''\n",
    "    This function is used to find the coefficient value for each feature by the logistic refression model. X_train is changed \n",
    "    based on the model X1,X2,X3,X4 and X5 and y_train is changed according to the target.\n",
    "    '''\n",
    "    mod_log = OrderedModel(y_train,X_train,distr='logit')\n",
    "    res_log = mod_log.fit(method='bfgs', disp=False)\n",
    "    return res_log.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53799fe5",
   "metadata": {},
   "source": [
    "## Percentile figure plot  for Diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ef4d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Fd=data[data['dibaHbA1C']==1]\n",
    "data_Fnd =data[data['dibaHbA1C']==0]\n",
    "percentiles = np.linspace(0,1,1000)\n",
    "r1 = data_Fd['generate waistc'].quantile(percentiles)\n",
    "r2 = data_Fnd['generate waistc'].quantile(percentiles)\n",
    "plt.plot(percentiles,r1)\n",
    "plt.plot(percentiles,r2)\n",
    "legend(['Diabetic Female','Non-diabetic Female'],fontsize=18)\n",
    "plt.xlabel('Percentiles',fontsize=18)\n",
    "plt.ylabel('Freuency',fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdc1d65",
   "metadata": {},
   "source": [
    "## Percentile plot for Hypertension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8948d5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Fd =data[data['htnbin']==1]\n",
    "data_Fnd =data[data['htnbin']==0]\n",
    "percentiles = np.linspace(0,1,1000)\n",
    "r1 = data_Fd['WholeBodyFatPerc'].quantile(percentiles)\n",
    "r2 = data_Fnd['WholeBodyFatPerc'].quantile(percentiles)\n",
    "plt.plot(percentiles,r1)\n",
    "plt.plot(percentiles,r2)\n",
    "legend(['Hypertension Female','Non-hypertension Female'],fontsize=18,loc='upper right')\n",
    "plt.xlabel('Percentiles',fontsize=18)\n",
    "plt.ylabel('Freuency',fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab28dd31",
   "metadata": {},
   "source": [
    "## Percentile Plot for ability to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d49351",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Fd =data[data['binary_ability']==1]\n",
    "data_Fnd =data[data['binary_ability']==0]\n",
    "percentiles = np.linspace(0,1,1000)\n",
    "r1 = data_Fd['meangripboth'].quantile(percentiles)\n",
    "r2 = data_Fnd['meangripboth'].quantile(percentiles)\n",
    "plt.plot(percentiles,r1)\n",
    "plt.plot(percentiles,r2)\n",
    "legend(['Female who are able to do work','Female who are not able to do work'],fontsize=14,loc='upper right')\n",
    "plt.xlabel('Percentiles',fontsize=18)\n",
    "plt.ylabel('Freuency',fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6b60dc",
   "metadata": {},
   "source": [
    "## ROC curve plot code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05badf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(max_iter=1000)\n",
    "model_score=logreg.fit(X_train, y_train)\n",
    "y_pred_proba = logreg.predict_proba(X_test)[::,1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
    "auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {auc:.3f}\")\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='No Skill')\n",
    "plt.ylabel('True Positive Rate',fontsize=18)\n",
    "plt.xlabel('False Positive Rate',fontsize=18)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec5e901",
   "metadata": {},
   "source": [
    "##  Waist circumference sensitivity and specificity for diabetes across potential screening cutoff values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e940c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_df = data[(data['generate waistc'] >= 70) & (data['generate waistc'] <= 100)]\n",
    "# Calculate sensitivity and specificity\n",
    "sensitivity_values = []\n",
    "specificity_values = []\n",
    "thresholds = []\n",
    "\n",
    "for threshold in range(70, 101):\n",
    "    threshold_df = subset_df.copy()\n",
    "    threshold_df['predicted_diabetes'] = (threshold_df['generate waistc'] >= threshold).astype(int)\n",
    "    tn, fp, fn, tp = metrics.confusion_matrix(threshold_df['dibaHbA1C'], threshold_df['predicted_diabetes']).ravel()\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity_values.append(sensitivity)\n",
    "    specificity_values.append(specificity)\n",
    "    thresholds.append(threshold)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(thresholds, sensitivity_values, label='Sensitivity')\n",
    "plt.plot(thresholds, specificity_values, label='Specificity')\n",
    "plt.xlabel('Waist circumference cutoff value',fontsize=18)\n",
    "plt.ylabel('Sensitivity/Specifity',fontsize=18)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd87dde7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
